import chardet

# # detect file encoding
# with open("text_1.txt", "rb") as f:
#     raw_data = f.read(6000)
#     result = chardet.detect(raw_data)
#     print(result)

# exit()

import timeit
import statistics

# --- –ê–ª–≥–æ—Ä–∏—Ç–º–∏ –ø–æ—à—É–∫—É --- #
def kmp_search(text, pattern):
    n, m = len(text), len(pattern)
    if m == 0:
        return -1
    lps = [0] * m
    j = 0
    i = 1
    while i < m:
        if pattern[i] == pattern[j]:
            j += 1
            lps[i] = j
            i += 1
        else:
            if j != 0:
                j = lps[j - 1]
            else:
                lps[i] = 0
                i += 1
    i = j = 0
    while i < n:
        if text[i] == pattern[j]:
            i += 1
            j += 1
        if j == m:
            return i - j
        elif i < n and text[i] != pattern[j]:
            if j != 0:
                j = lps[j - 1]
            else:
                i += 1
    return -1


def rabin_karp_search(text, pattern, q=101):
    d = 256
    n, m = len(text), len(pattern)
    if m == 0 or m > n:
        return -1
    p = t = 0
    h = 1
    for i in range(m - 1):
        h = (h * d) % q
    for i in range(m):
        p = (d * p + ord(pattern[i])) % q
        t = (d * t + ord(text[i])) % q
    for i in range(n - m + 1):
        if p == t and text[i:i + m] == pattern:
            return i
        if i < n - m:
            t = (d * (t - ord(text[i]) * h) + ord(text[i + m])) % q
            if t < 0:
                t += q
    return -1


def boyer_moore_search(text, pattern):
    n, m = len(text), len(pattern)
    if m == 0:
        return -1
    bad_char = {ch: i for i, ch in enumerate(pattern)}
    s = 0
    while s <= n - m:
        j = m - 1
        while j >= 0 and pattern[j] == text[s + j]:
            j -= 1
        if j < 0:
            return s
        s += max(1, j - bad_char.get(text[s + j], -1))
    return -1


# --- –ë–µ–∑–ø–µ—á–Ω–µ —á–∏—Ç–∞–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤ --- #
def safe_read(filename):
    for enc in ("utf-8-sig", "cp1251", "utf-8", "iso-8859-1"):
        try:
            with open(filename, encoding=enc) as f:
                return f.read()
        except UnicodeDecodeError:
            continue
    raise UnicodeDecodeError(f"Cannot decode {filename} with common encodings.")


text1 = safe_read("text_1.txt")
text2 = safe_read("text_2.txt")

patterns = {
    "text_1": ("–∞–ª–≥–æ—Ä–∏—Ç–º", "xyz123"),
    "text_2": ("—Å–∏—Å—Ç–µ–º–∞", "qwerty999"),
}


# --- Benchmark single run --- #
def benchmark(text, pattern, func):
    return timeit.timeit(lambda: func(text, pattern), number=1)


# --- Run multiple independent tests --- #
def run_tests(repeats=10):
    algorithms = [boyer_moore_search, kmp_search, rabin_karp_search]

    # wins per text, separately for existing and fake patterns
    wins_exist = {name: {f.__name__: 0 for f in algorithms} for name in patterns}
    wins_fake  = {name: {f.__name__: 0 for f in algorithms} for name in patterns}

    for name, (p_exist, p_fake) in patterns.items():
        text = text1 if name == "text_1" else text2
        print(f"\n=== {name} ===")

        for i in range(repeats):
            times_exist = {}
            times_fake = {}

            for func in algorithms:
                t_exist = benchmark(text, p_exist, func)
                t_fake  = benchmark(text, p_fake,  func)
                times_exist[func.__name__] = t_exist
                times_fake[func.__name__]  = t_fake

            best_exist = min(times_exist, key=times_exist.get)
            best_fake  = min(times_fake,  key=times_fake.get)

            wins_exist[name][best_exist] += 1
            wins_fake[name][best_fake]   += 1

            print(f"[{i+1}/{repeats}] –Ω–∞–π—à–≤–∏–¥—à—ñ ‚Äî {best_exist} (—ñ—Å–Ω—É—é—á–∏–π), {best_fake} (–≤–∏–≥–∞–¥–∞–Ω–∏–π)")

    return wins_exist, wins_fake, repeats


# --- Entry point --- #
if __name__ == "__main__":
    wins_exist, wins_fake, repeats = run_tests(repeats=10)

    print("\n=== –ü–Ü–î–°–£–ú–ö–û–í–ê –°–¢–ê–¢–ò–°–¢–ò–ö–ê (–ø–æ-—Ç–µ–∫—Å—Ç–æ–≤–æ) ===")
    print(f"üîπ –ö—ñ–ª—å–∫—ñ—Å—Ç—å –Ω–µ–∑–∞–ª–µ–∂–Ω–∏—Ö –ø—Ä–æ–≥–æ–Ω—ñ–≤ –Ω–∞ —Ç–µ–∫—Å—Ç: {repeats}")

    for name in patterns:
        print(f"\n‚Äî {name} ‚Äî")
        print("üìà –ü–µ—Ä–µ–º–æ–≥–∏ –ø—Ä–∏ –ø–æ—à—É–∫—É –Ü–°–ù–£–Æ–ß–û–ì–û –ø—ñ–¥—Ä—è–¥–∫–∞:")
        for algo, wins in wins_exist[name].items():
            print(f"{algo:20s}: {wins} –ø–µ—Ä–µ–º–æ–≥")
        best_exist_text = max(wins_exist[name], key=wins_exist[name].get)

        print("\nüìâ –ü–µ—Ä–µ–º–æ–≥–∏ –ø—Ä–∏ –ø–æ—à—É–∫—É –í–ò–ì–ê–î–ê–ù–û–ì–û –ø—ñ–¥—Ä—è–¥–∫–∞:")
        for algo, wins in wins_fake[name].items():
            print(f"{algo:20s}: {wins} –ø–µ—Ä–µ–º–æ–≥")
        best_fake_text = max(wins_fake[name], key=wins_fake[name].get)

        print("\n=== –í–ò–°–ù–û–í–û–ö (–¥–ª—è —Ü—å–æ–≥–æ —Ç–µ–∫—Å—Ç—É) ===")
        print(f"üîπ –ù–∞–π—á–∞—Å—Ç—ñ—à–µ –Ω–∞–π—à–≤–∏–¥—à–∏–º –¥–ª—è —ñ—Å–Ω—É—é—á–∏—Ö –ø—ñ–¥—Ä—è–¥–∫—ñ–≤ –±—É–≤: {best_exist_text} ({wins_exist[name][best_exist_text]} –∑ {repeats})")
        print(f"üîπ –ù–∞–π—á–∞—Å—Ç—ñ—à–µ –Ω–∞–π—à–≤–∏–¥—à–∏–º –¥–ª—è –≤–∏–≥–∞–¥–∞–Ω–∏—Ö –ø—ñ–¥—Ä—è–¥–∫—ñ–≤ –±—É–≤: {best_fake_text} ({wins_fake[name][best_fake_text]} –∑ {repeats})")
